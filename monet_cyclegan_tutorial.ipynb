{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "##Installs\n",
    "!pip install 'tensorflow_addons' 'tensorflow-determinism' 'gdown'\n",
    "\n",
    "##Imports\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.data.ops.dataset_ops import Dataset\n",
    "from tensorflow.python.distribute.tpu_strategy import TPUStrategy\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "\n",
    "#Environment setup\n",
    "##Set random seed\n",
    "def set_training_random_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    print(f'set_training_random_seed() - seed value: {seed}')\n",
    "\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "set_training_random_seed(RANDOM_SEED)\n",
    "\n",
    "##Connect to strongest available device\n",
    "def choose_strongest_available_device_strategy():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        selected_strategy = TPUStrategy(tpu)\n",
    "    except:\n",
    "        selected_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "    print(f\"choose_strongest_available_device_strategy() - selected strategy type: {type(selected_strategy).__name__}\")\n",
    "    gpu_is_available = any(tf.config.list_physical_devices('GPU'))\n",
    "    if gpu_is_available:\n",
    "        !nvidia-smi\n",
    "\n",
    "    return selected_strategy\n",
    "\n",
    "DEVICE_STRATEGY = choose_strongest_available_device_strategy()\n",
    "\n",
    "# todo itay - delete\n",
    "assert tf.__version__ == '2.6.4'\n",
    "\n",
    "##Download competition dataset\n",
    "LOCAL_DATASET_FOLDER_PATH = Path('./train_data/gan-getting-started/')\n",
    "\n",
    "def download_competition_dataset_if_not_present():\n",
    "    if not LOCAL_DATASET_FOLDER_PATH.exists():\n",
    "        # note - this is the untouched competition dataset. just uploaded it to the drive so it'll be\n",
    "        # available via colab as well.\n",
    "        !gdown 1ZwcoO11NKhYsbuM7hzdSzKjGOnOx6X94\n",
    "        !mkdir -p {LOCAL_DATASET_FOLDER_PATH}\n",
    "        !unzip -o -q ./gan-getting-started.zip -d {LOCAL_DATASET_FOLDER_PATH}\n",
    "\n",
    "download_competition_dataset_if_not_present()\n",
    "\n",
    "#Load competition dataset\n",
    "##Load full dataset\n",
    "def find_competition_dataset_files():\n",
    "    if isinstance(DEVICE_STRATEGY, TPUStrategy):\n",
    "        from kaggle_datasets import KaggleDatasets\n",
    "        dataset_folder_path = Path(KaggleDatasets().get_gcs_path())\n",
    "    else:\n",
    "        dataset_folder_path = LOCAL_DATASET_FOLDER_PATH\n",
    "\n",
    "    monet_dataset_files_ = tf.io.gfile.glob(str(dataset_folder_path / 'monet_tfrec/*.tfrec'))\n",
    "    photo_dataset_files_ = tf.io.gfile.glob(str(dataset_folder_path / 'photo_tfrec/*.tfrec'))\n",
    "    assert any(monet_dataset_files_)\n",
    "    assert any(photo_dataset_files_)\n",
    "    return monet_dataset_files_, photo_dataset_files_\n",
    "\n",
    "\n",
    "def load_tf_records_dataset(tf_record_files) -> Dataset:\n",
    "    def _read_and_normalize_tfrecord(record):\n",
    "        tfrecord_format = {\n",
    "            \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "        record = tf.io.parse_single_example(record, tfrecord_format)\n",
    "        image = record['image']\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        # print(f'asdsadsad: {(image.shape, type(image))}')\n",
    "        # image = tf.keras.utils.array_to_img(image)\n",
    "        # image = image.resize((320, 320))\n",
    "        # image = np.array(image)\n",
    "        # image = tf.convert_to_tensor(image)\n",
    "        image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "        image = tf.reshape(image, [256, 256, 3])\n",
    "        image = tf.image.resize(image, (320, 320), method='bilinear')\n",
    "        return image\n",
    "\n",
    "    sorted_tf_record_files = sorted(tf_record_files)\n",
    "    dataset = tf.data.TFRecordDataset(sorted_tf_record_files)\n",
    "    dataset = dataset.map(_read_and_normalize_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "monet_dataset_files, photo_dataset_files = find_competition_dataset_files()\n",
    "monet_ds = load_tf_records_dataset(monet_dataset_files).batch(1)\n",
    "photo_ds = load_tf_records_dataset(photo_dataset_files).batch(1)\n",
    "\n",
    "\n",
    "##Pick 30 train monet images\n",
    "def pick_images_farthest_from_each_other(monet_images_dataset: Dataset, images_count: int) -> Dataset:\n",
    "    def _images_distance(im1, im2):\n",
    "        distance = np.sum((im1.numpy().flatten() - im2.numpy().flatten()) ** 2)\n",
    "        return distance\n",
    "\n",
    "    farthest_images_list = incremental_farthest_search(\n",
    "        list(monet_images_dataset), k=images_count, distance_func=_images_distance\n",
    "    )\n",
    "    farthest_images_dataset = Dataset.from_tensor_slices(farthest_images_list)\n",
    "    return farthest_images_dataset\n",
    "\n",
    "\n",
    "def pick_random_images(monet_images_dataset: Dataset, images_count: int) -> Dataset:\n",
    "    monet_images_list = list(monet_images_dataset)\n",
    "    return Dataset.from_tensor_slices([\n",
    "        monet_images_list[image_idx]\n",
    "        for image_idx in np.random.choice(\n",
    "            list(range(len(monet_images_list))), size=images_count, replace=False\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "def incremental_farthest_search(array, k: int, distance_func):\n",
    "    remaining_points = array[:]\n",
    "    solution_set = [remaining_points.pop(random.randint(0, len(remaining_points) - 1))]\n",
    "\n",
    "    for _ in tqdm(list(range(k - 1)), desc='incremental_farthest_search() main loop'):\n",
    "        distances = [distance_func(p, solution_set[0]) for p in remaining_points]\n",
    "        for i, p in enumerate(remaining_points):\n",
    "            for j, s in enumerate(solution_set):\n",
    "                distances[i] = min(distances[i], distance_func(p, s))\n",
    "        solution_set.append(remaining_points.pop(distances.index(max(distances))))\n",
    "    return solution_set\n",
    "\n",
    "\n",
    "# monet_ds = pick_images_farthest_from_each_other(\n",
    "#     monet_images_dataset=monet_ds,\n",
    "#     images_count=30\n",
    "# )\n",
    "\n",
    "np.random.seed(42)\n",
    "TRAIN_IMAGES_COUNT = 30\n",
    "monet_ds = pick_random_images(\n",
    "    monet_images_dataset=monet_ds,\n",
    "    images_count=TRAIN_IMAGES_COUNT\n",
    ")\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "images_shape = list(monet_ds)[0].shape\n",
    "print(f\"*** input train images (shape: {images_shape})***\")\n",
    "_, ax = plt.subplots(TRAIN_IMAGES_COUNT, 1, figsize=(50, 50))\n",
    "for i, img in enumerate(monet_ds):\n",
    "    img = (img * 127.5 + 127.5).numpy()[0].astype(np.uint8)\n",
    "\n",
    "    ax[i].imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def down_sample(filters, size, strides=2, padding='same'):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    network = keras.Sequential()\n",
    "    network.add(layers.Conv2D(filters, size, strides=strides, padding=padding,\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    network.add(layers.LeakyReLU())\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def up_sample(filters, size, strides=2, padding='same', apply_dropout=False):\n",
    "    network = keras.Sequential()\n",
    "    network.add(layers.Conv2DTranspose(\n",
    "        filters, size, strides=strides, padding=padding, use_bias=False,\n",
    "        kernel_initializer=tf.random_normal_initializer(0., 0.02)\n",
    "    ))\n",
    "    if apply_dropout:\n",
    "        network.add(layers.Dropout(0.5))\n",
    "    network.add(layers.ReLU())\n",
    "    return network\n",
    "\n",
    "\n",
    "def construct_generator():\n",
    "    inputs = layers.Input(shape=[320, 320, 3])\n",
    "\n",
    " # bs = batch size\n",
    "    down_stack = [\n",
    "        down_sample(64, 4), # (bs, 160, 160, 64)\n",
    "        down_sample(128, 4), # (bs, 80, 80, 128)\n",
    "        down_sample(256, 4), # (bs, 40, 40, 256)\n",
    "        down_sample(512, 4), # (bs, 20, 20, 512)\n",
    "        down_sample(512, 4), # (bs, 10, 10, 512)\n",
    "        down_sample(512, 4), # (bs, 5, 5, 512)\n",
    "        down_sample(512, 4, strides=1, padding='valid'), # (bs, 2, 2, 512)?\n",
    "        down_sample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        up_sample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        up_sample(512, 4, strides=1, padding='valid', apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        up_sample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        up_sample(512, 4), # (bs, 16, 16, 1024)\n",
    "        up_sample(256, 4), # (bs, 32, 32, 512)\n",
    "        up_sample(128, 4), # (bs, 64, 64, 256)\n",
    "        up_sample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = layers.Conv2DTranspose(3, 4,\n",
    "                                  strides=2,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "\n",
    "    generator_model = keras.Model(inputs=inputs, outputs=x)\n",
    "    return generator_model\n",
    "\n",
    "\"\"\"# Build the discriminator\n",
    "\n",
    "The discriminator takes in the input image and classifies it as real or fake (generated). Instead of outputing a single node, the discriminator outputs a smaller 2D image with higher pixel values indicating a real classification and lower values indicating a fake classification.\n",
    "\"\"\"\n",
    "\n",
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = layers.Input(shape=[320, 320, 3], name='input_image')\n",
    "\n",
    "    x = inp\n",
    "\n",
    "    down1 = down_sample(64, 5)(x) # (bs, 160, 160, 64)\n",
    "    down2 = down_sample(128, 4)(down1) # (bs, 80, 80, 128)\n",
    "    down3 = down_sample(256, 3)(down2) # (bs, 40, 40, 256)\n",
    "    down4 = down_sample(256, 2)(down3) # (bs, 20, 20, 256)\n",
    "\n",
    "    zero_pad1 = layers.ZeroPadding2D()(down4) # (bs, 34, 34, 256)\n",
    "    conv = layers.Conv2D(512, 4, strides=1,\n",
    "                         kernel_initializer=initializer,\n",
    "                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    leaky_relu = layers.LeakyReLU()(conv)\n",
    "\n",
    "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = layers.Conv2D(1, 4, strides=1,\n",
    "                         kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    discriminator_model = tf.keras.Model(inputs=inp, outputs=last)\n",
    "    return discriminator_model\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    monet_generator = construct_generator() # transforms photos to Monet-esque paintings\n",
    "    photo_generator = construct_generator() # transforms Monet paintings to be more like photos\n",
    "\n",
    "    monet_discriminator = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n",
    "    photo_discriminator = Discriminator() # differentiates real photos and generated photos\n",
    "    monet_discriminator.summary()\n",
    "\n",
    "\n",
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monet_generator,\n",
    "        photo_generator,\n",
    "        monet_discriminator,\n",
    "        photo_discriminator,\n",
    "        lambda_cycle=10,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        m_gen_optimizer,\n",
    "        p_gen_optimizer,\n",
    "        m_disc_optimizer,\n",
    "        p_disc_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        real_monet, real_photo = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # photo to monet back to photo\n",
    "            fake_monet = self.m_gen(real_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "\n",
    "            # monet to photo back to monet\n",
    "            fake_photo = self.p_gen(real_monet, training=True)\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "\n",
    "            # generating itself\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing real images\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing fake images\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "\n",
    "            # evaluates generator loss\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            # evaluates total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates total generator loss\n",
    "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "\n",
    "            # evaluates discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
    "                                                  self.m_gen.trainable_variables)\n",
    "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
    "                                                  self.p_gen.trainable_variables)\n",
    "\n",
    "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
    "                                                      self.m_disc.trainable_variables)\n",
    "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
    "                                                      self.p_disc.trainable_variables)\n",
    "\n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
    "                                                 self.m_gen.trainable_variables))\n",
    "\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
    "                                                 self.p_gen.trainable_variables))\n",
    "\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
    "                                                  self.m_disc.trainable_variables))\n",
    "\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
    "                                                  self.p_disc.trainable_variables))\n",
    "\n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }\n",
    "\n",
    "\"\"\"# Define loss functions\n",
    "\n",
    "The discriminator loss function below compares real images to a matrix of 1s and fake images to a matrix of 0s. The perfect discriminator will output all 1s for real images and all 0s for fake images. The discriminator loss outputs the average of the real and generated loss.\n",
    "\"\"\"\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    def discriminator_loss(real, generated):\n",
    "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
    "\n",
    "        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
    "\n",
    "        total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "        return total_disc_loss * 0.5\n",
    "\n",
    "\"\"\"The generator wants to fool the discriminator into thinking the generated image is real. The perfect generator will have the discriminator output only 1s. Thus, it compares the generated image to a matrix of 1s to find the loss.\"\"\"\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    def generator_loss(generated):\n",
    "        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)\n",
    "\n",
    "\"\"\"We want our original photo and the twice transformed photo to be similar to one another. Thus, we can calculate the cycle consistency loss be finding the average of their difference.\"\"\"\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
    "        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "        return LAMBDA * loss1\n",
    "\n",
    "\"\"\"The identity loss compares the image with its generator (i.e. photo with photo generator). If given a photo as input, we want it to generate the same image as the image was originally a photo. The identity loss compares the input with the output of the generator.\"\"\"\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    def identity_loss(real_image, same_image, LAMBDA):\n",
    "        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "        return LAMBDA * 0.5 * loss\n",
    "\n",
    "\"\"\"# Train the CycleGAN\n",
    "\n",
    "Let's compile our model. Since we used `tf.keras.Model` to build our CycleGAN, we can just ude the `fit` function to train our model.\n",
    "\"\"\"\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.001)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.001)\n",
    "\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.001)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.001)\n",
    "\n",
    "with DEVICE_STRATEGY.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer = monet_generator_optimizer,\n",
    "        p_gen_optimizer = photo_generator_optimizer,\n",
    "        m_disc_optimizer = monet_discriminator_optimizer,\n",
    "        p_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )\n",
    "\n",
    "print(f'\\n\\n*** running_on_tpu - {isinstance(DEVICE_STRATEGY, TPUStrategy)} ***\\n\\n')\n",
    "\n",
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((monet_ds, photo_ds)),\n",
    "    epochs=25,\n",
    "    # epochs=1,\n",
    ")\n",
    "\n",
    "\"\"\"# Visualize our Monet-esque photos\"\"\"\n",
    "\n",
    "_, ax = plt.subplots(5, 2, figsize=(12, 12))\n",
    "for i, img in enumerate(photo_ds.take(5)):\n",
    "    prediction = monet_generator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 1].imshow(prediction)\n",
    "    ax[i, 0].set_title(\"Input Photo\")\n",
    "    ax[i, 1].set_title(\"Monet-esque\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"# Create submission file\"\"\"\n",
    "CREATE_PREDICTIONS = True\n",
    "\n",
    "\n",
    "if CREATE_PREDICTIONS:\n",
    "    wip_images_folder = Path(f\"/tmp/wip_{datetime.now().strftime('%y_%m_%d__%H_%M_%S')}/\")\n",
    "    wip_images_folder.mkdir(parents=True, exist_ok=True)\n",
    "    output_zip_path = Path('/kaggle/working/images.zip')\n",
    "    if output_zip_path.exists():\n",
    "        output_zip_path.unlink()\n",
    "\n",
    "    with ZipFile(output_zip_path, 'w') as output_images_zip, \\\n",
    "        tqdm(total=7_038, desc='generating prediction images') as pbar:\n",
    "        for i, img in enumerate(photo_ds):\n",
    "            prediction = monet_generator(img, training=False)[0].numpy()\n",
    "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "            im = Image.fromarray(prediction)\n",
    "            wip_image_file_path = wip_images_folder / f'{i + 1}.jpg'\n",
    "            im.save(wip_image_file_path)\n",
    "            output_images_zip.write(filename=wip_image_file_path, arcname=wip_image_file_path.name)\n",
    "            wip_image_file_path.unlink()\n",
    "            pbar.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
